{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Getdcgaxtn1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "213573b2-2a40-4663-d1d9-d70fd88a6ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 13s 221ms/step - loss: 2.2028 - accuracy: 0.3624 - val_loss: 1.3001 - val_accuracy: 0.6173\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 3s 128ms/step - loss: 0.7693 - accuracy: 0.8438 - val_loss: 0.3436 - val_accuracy: 0.9388\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 3s 129ms/step - loss: 0.2673 - accuracy: 0.9680 - val_loss: 0.2494 - val_accuracy: 0.9745\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.1920 - accuracy: 0.9859 - val_loss: 0.2644 - val_accuracy: 0.9694\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 3s 123ms/step - loss: 0.1879 - accuracy: 0.9846 - val_loss: 0.2558 - val_accuracy: 0.9694\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 3s 126ms/step - loss: 0.1656 - accuracy: 0.9910 - val_loss: 0.2634 - val_accuracy: 0.9694\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 11s 144ms/step - loss: 0.2050 - accuracy: 0.9795 - val_loss: 0.1702 - val_accuracy: 0.9847\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.1512 - accuracy: 0.9872 - val_loss: 0.1298 - val_accuracy: 0.9898\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 4s 165ms/step - loss: 0.1188 - accuracy: 0.9987 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 4s 154ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 3s 125ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 11s 149ms/step - loss: 0.0650 - accuracy: 0.9962 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 4s 144ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 3s 128ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 3s 121ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 4s 159ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 3s 121ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 3s 120ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 11s 144ms/step - loss: 0.0144 - accuracy: 0.9987 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.0168 - accuracy: 0.9974 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 3s 134ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 4s 147ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 3s 128ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 3s 128ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 4s 149ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 3s 125ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 11s 150ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 3s 122ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 3s 123ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 4s 165ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 3s 126ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 3s 128ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.9573e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 4s 144ms/step - loss: 8.6231e-04 - accuracy: 1.0000 - val_loss: 7.6066e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 3s 123ms/step - loss: 7.4401e-04 - accuracy: 1.0000 - val_loss: 6.6431e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 3s 124ms/step - loss: 6.5808e-04 - accuracy: 1.0000 - val_loss: 5.8605e-04 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import joblib\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = tf.keras.layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = tf.keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    x = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n",
        "\n",
        "def create_transformer_model(df):\n",
        "    inputs = tf.keras.layers.Input(shape=(None, ), dtype=tf.int32)\n",
        "    x = tf.keras.layers.Embedding(input_dim=5000, output_dim=16)(inputs)\n",
        "    x = transformer_encoder(x, head_size=256, num_heads=4, ff_dim=4*256, dropout=0.1)\n",
        "    x = transformer_encoder(x, head_size=256, num_heads=4, ff_dim=4*256, dropout=0.1)\n",
        "    x = transformer_encoder(x, head_size=256, num_heads=4, ff_dim=4*256, dropout=0.1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = tf.keras.layers.Dense(len(df['internalStatus'].unique()), activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def preprocess_data(df):\n",
        "    # Tokenize the 'externalStatus' column\n",
        "    tokenizer = Tokenizer(num_words=5000, oov_token=\"OOV\")\n",
        "    tokenizer.fit_on_texts(df['externalStatus'])\n",
        "    X = tokenizer.texts_to_sequences(df['externalStatus'])\n",
        "    X = pad_sequences(X, padding='post')\n",
        "\n",
        "    # Encode the 'internalStatus' column\n",
        "    encoder = LabelEncoder()\n",
        "    y = encoder.fit_transform(df['internalStatus'])\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Save tokenizer and encoder\n",
        "    joblib.dump(tokenizer, 'tokenizer.joblib')\n",
        "    joblib.dump(encoder, 'encoder.joblib')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, tokenizer, encoder\n",
        "\n",
        "def train_model(X_train, y_train, model):\n",
        "    # Initialize the StratifiedKFold class\n",
        "    skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "    # Loop over each split\n",
        "    for train_index, val_index in skf.split(X_train, y_train):\n",
        "        # Split the data\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model with early stopping\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "        history = model.fit(X_train_fold, y_train_fold, epochs=10, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load the data\n",
        "url = \"https://gist.githubusercontent.com/farhaan-settyl/ecf9c1e7ab7374f18e4400b7a3d2a161/raw/f94652f217eeca83e36dab9d08727caf79ebdecf/dataset.json\"\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "df = pd.json_normalize(data)\n",
        "\n",
        "# Preprocess the data\n",
        "X_train, X_test, y_train, y_test, tokenizer, encoder = preprocess_data(df)\n",
        "\n",
        "# Create the model\n",
        "model = create_transformer_model(df)\n",
        "\n",
        "# Train the model\n",
        "model = train_model(X_train, y_train, model)\n",
        "\n",
        "# Save the model\n",
        "model.save('transformer_model.h5')\n",
        "\n",
        "model.save_weights('transformer_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = df['internalStatus'].nunique()\n",
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLAxJVtMWC46",
        "outputId": "6f700bed-b7c8-4127-a74d-91588935b2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJuhHIU-WHCZ",
        "outputId": "e8df65a2-ba6b-4b4d-8940-d2c7976e64ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show keras"
      ],
      "metadata": {
        "id": "n7cRS5_Bl68h",
        "outputId": "81af837e-3c73-42ac-fe5e-c1c3e516e93f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: keras\n",
            "Version: 2.15.0\n",
            "Summary: Deep learning for humans.\n",
            "Home-page: https://keras.io/\n",
            "Author: Keras team\n",
            "Author-email: keras-users@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCbctJtdGDAP",
        "outputId": "6717e424-6a72-4d98-c672-c765d93ad7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: scikit-learn\n",
            "Version: 1.2.2\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: http://scikit-learn.org\n",
            "Author: \n",
            "Author-email: \n",
            "License: new BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: joblib, numpy, scipy, threadpoolctl\n",
            "Required-by: bigframes, fastai, imbalanced-learn, librosa, mlxtend, qudida, sklearn-pandas, yellowbrick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "NxwZUGaNGGst",
        "outputId": "520df796-9cef-4be6-8a02-0f11451affaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "un9TmJmqiyXm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}